{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Huggung_face_Introduction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUPb/DcSFV/TWqavnPvyvh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_8JdaN_TY4r",
        "outputId": "d9a67213-575e-4ff0-8782-da6b02efa279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.96)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[sentencepiece]\n",
        "import transformers\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
        "classifier_zero_shot_classification = pipeline(\"zero-shot-classification\")\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "generator_distilgpt2 = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "634Z1g0reZ_2",
        "outputId": "2b917b53-100d-4ec1-cf07-765336b1bd53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n",
            "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
            "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n",
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/token_classification.py:136: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  f'`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"{aggregation_strategy}\"` instead.'\n",
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:196: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_sentiment_analysis(\"I've been waiting for a HuggingFace course my whole life.\")"
      ],
      "metadata": {
        "id": "ESoyarIqVNrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4cc2d8-dd4f-4ddb-f1d9-851dc1a28b19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598048329353333}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_sentiment_analysis(\n",
        "    [\"Coaches and teammates can help each other play better with encouraging words.\", \n",
        "     \"These aren't pistachios.\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf1b7_FebbN8",
        "outputId": "57ef07eb-54e6-4190-a485-61ff59dd8192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9993155002593994},\n",
              " {'label': 'NEGATIVE', 'score': 0.9839645624160767}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_zero_shot_classification(\n",
        "    \"If teachers can help their students feel motivated and upbeat, they will learn better.\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvfBisgUbhU0",
        "outputId": "1561398a-e98e-4ea6-c574-5ca2e1f24a63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.9135254621505737, 0.06462164968252182, 0.021852940320968628],\n",
              " 'sequence': 'If teachers can help their students feel motivated and upbeat, they will learn better.'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_generator(\"She won't be attending the Met Gala this year as\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-mqFksdbpds",
        "outputId": "78f5b856-ff39-40fb-f2f3-3d6fb0bea696"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'She won\\'t be attending the Met Gala this year as it will be televised on a more mobile platform,\" said Mounaradane, referring to the show.\\n\\nHowever, due to the upcoming holiday season, the group announced this summer'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator_distilgpt2(\n",
        "    \"She did not like Bikhram yoga because\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOhTPwq8b9Ir",
        "outputId": "4ac3e4ac-f631-409e-c3ad-7e31f301ace9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'She did not like Bikhram yoga because I felt uncomfortable. So I found some yoga classes that didn\\'t help me.\"\\n\\n\\n\\n\\n'},\n",
              " {'generated_text': 'She did not like Bikhram yoga because he loved it.\"\\n\\n\\n- The views expressed are the author\\'s own.\\n\\n\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"All I have left is the conclusion, but I don’t <mask> to work on it!\", top_k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjXhjk_GdRfG",
        "outputId": "67ac83ee-0528-480f-a1ba-2dbe7868bfec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.546733021736145,\n",
              "  'sequence': 'All I have left is the conclusion, but I don’t want to work on it!',\n",
              "  'token': 236,\n",
              "  'token_str': ' want'},\n",
              " {'score': 0.2555423676967621,\n",
              "  'sequence': 'All I have left is the conclusion, but I don’t intend to work on it!',\n",
              "  'token': 10557,\n",
              "  'token_str': ' intend'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvJziFbRdbO1",
        "outputId": "51234b59-f54f-4916-f0df-16ce384a7559"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 18,\n",
              "  'entity_group': 'PER',\n",
              "  'score': 0.9981694,\n",
              "  'start': 11,\n",
              "  'word': 'Sylvain'},\n",
              " {'end': 45,\n",
              "  'entity_group': 'ORG',\n",
              "  'score': 0.9796019,\n",
              "  'start': 33,\n",
              "  'word': 'Hugging Face'},\n",
              " {'end': 57,\n",
              "  'entity_group': 'LOC',\n",
              "  'score': 0.9932106,\n",
              "  'start': 49,\n",
              "  'word': 'Brooklyn'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MFSpJdj3F",
        "outputId": "ab0ee2f1-b607-442e-f2fc-e7c1440b016e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Hugging Face', 'end': 45, 'score': 0.6949766278266907, 'start': 33}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Rabindranath Tagore began to write drama from sixteen years of age. At the age of twenty, Rabindranath Tagore wrote original dramatic piece Valmiki Pratibha. Most noteworthy, Rabindranath Tagore works focused on feelings and not on action. In 1890 he wrote another drama work Visarjan. Visarjan is probably the best drama work of Rabindranath Tagore.\n",
        "\n",
        "    Similarly, from the age of sixteen Rabindranath Tagore began to write short stories. His first short story was Bhikarini. Most noteworthy, he is the founder of the Bengali-language short story genre. Tagore certainly wrote numerous stories from 1891 to 1895. Also, stories from this period form the collection of Galpaguchchha. It is a big collection of 84 stories.\n",
        "\n",
        "    Rabindranath Tagore was certainly in touch with novels as well. He wrote eight notable novels. Furthermore, he wrote four novellas.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMAufxX9dzQk",
        "outputId": "20bb0c3e-dbb8-4edb-cd33-2514cdaa5a98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' At the age of sixteen, Rabindranath Tagore began to write short stories . His first short story was published in 1891 . He wrote eight novels and four novellas from 1891 to 1892 . He also wrote a series of short stories about life in the 1930s .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEHHwibWd84d",
        "outputId": "22ea485c-86b1-4e4a-fccd-7aea058cf297"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by Hugging Face.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfrutZT1eRrd",
        "outputId": "115821c9-1a32-4f11-f23e-60c033ec75b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
            "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j4EeXt0ri69O"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}